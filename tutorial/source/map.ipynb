{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from pyro.contrib.gp import models\n",
    "import pyro.distributions as dist\n",
    "from torch.nn import Parameter\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI\n",
    "from pyro.contrib.gp.util import Parameterized\n",
    "from torch.distributions import constraints\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Goal: Understand MAP interfences in Pyro.\n",
    "Reusing our coin flipping example in last tutorial, only this time we want to use Maximise A Posterior(MAP), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coin(Parameterized):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_alpha = Parameter(torch.tensor([10.0]))\n",
    "        self.log_beta = Parameter(torch.tensor([10.0]))\n",
    "        self.set_constraint(\"log_alpha\", constraints.positive)\n",
    "        self.set_constraint(\"log_beta\", constraints.positive)\n",
    "        \n",
    "        \n",
    "    def model(self, data):\n",
    "        self.set_mode('model')\n",
    "        alpha = self.get_param('log_alpha')\n",
    "        beta = self.get_param('log_beta')\n",
    "        f = pyro.sample('latent_fairness', dist.Beta(torch.exp(alpha), torch.exp(beta)))\n",
    "        for i in range(len(data)):\n",
    "            pyro.sample('obs_{}'.format(i), dist.Bernoulli(f), obs=data[i])\n",
    "    \n",
    "    def guide(self, data):\n",
    "        self.set_mode('guide')\n",
    "        alpha = self.get_param('log_alpha')\n",
    "        beta = self.get_param('log_beta')\n",
    "        f = pyro.sample('latent_fairness', dist.Beta(torch.exp(alpha), torch.exp(beta)))\n",
    "        #pyro.sample('latent_fairness', dist.Delta, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the data that we observe when flipping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.ones(1))\n",
    "for _ in range(4):\n",
    "    data.append(torch.zeros(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same procedure in SVI tutorial I to optimise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "coin = Coin()\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(coin.model, coin.guide, optimizer, loss=\"ELBO\")\n",
    "\n",
    "n_steps = 4000\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    svi.step(data)\n",
    "    if step % 100 == 0:\n",
    "        print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_q = torch.exp(coin.get_param(\"log_alpha\")).data.numpy()[0]\n",
    "beta_q = torch.exp(coin.get_param(\"log_beta\")).data.numpy()[0]\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * np.sqrt(factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.601 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
